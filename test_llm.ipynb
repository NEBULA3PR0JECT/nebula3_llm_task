{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple\n",
    "import multiprocessing as mp\n",
    "from llm_orchestration import *\n",
    "from experts.pipeline.api import PipelineApi, PipelineTask\n",
    "sys.path.insert(0, \"/notebooks/nebula3_experiments\")\n",
    "from vg_eval import VGEvaluation, get_sc_graph, spice_get_triplets, tuples_from_sg\n",
    "from prompts_utils import get_likey_tuples_from_paragraph\n",
    "# from movie.movie_db import MOVIE_DB\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline as transformer_pipeline, set_seed, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from langchain import HuggingFaceHub, OpenAI\n",
    "from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "# EVAL_COLLECTION_NAME = 's4_eval_output'\n",
    "EVAL_COLLECTION_NAME = 's4_eval_gpt_output'\n",
    "\n",
    "def test_pipeline_task(pipeline_id):\n",
    "    class LlmTask(PipelineTask):\n",
    "        def __init__(self):\n",
    "            self.llm_task = LlmTaskInternal()\n",
    "            print(\"LlmTask Initialized successfully.\")\n",
    "\n",
    "        def process_movie(self, movie_id: str) -> Tuple[bool, str]:\n",
    "            print (f'LlmTask: handling movie: {movie_id}')\n",
    "\n",
    "            output = self.llm_task.process_movie(movie_id)\n",
    "\n",
    "            print(\"LlmTask: Finished handling movie.\")\n",
    "            print(output)\n",
    "            return output\n",
    "        def get_name(self) -> str:\n",
    "            return \"llm\"\n",
    "\n",
    "    pipeline = PipelineApi(None)\n",
    "    task = LlmTask()\n",
    "    pipeline.handle_pipeline_task(task, pipeline_id, stop_on_failure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = PipelineApi(None)\n",
    "\n",
    "class LLMBase(ABC):\n",
    "    @abstractmethod\n",
    "    def completion(prompt_template: str, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "class HuggingFaceLLM(LLMBase):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def completion(self, prompt_template: str, *args, **kwargs):\n",
    "        prompt = prompt_template.format(*args)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        outputs = self.model.generate(inputs, **kwargs)\n",
    "        return [self.tokenizer.decode(x) for x in outputs]\n",
    "        \n",
    "\n",
    "class OptLLM(LLMBase):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def completion(self, prompt_template: str, *args, **kwargs):\n",
    "        prompt = prompt_template.format(*args)\n",
    "        response = self.model(prompt, max_new_tokens=256, max_length=len(prompt)+256, **kwargs)\n",
    "        return [x['generated_text'].strip() for x in response]        \n",
    "\n",
    "def gpt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)   \n",
    "    response = openai.Completion.create(prompt=prompt, max_tokens=256, **kwargs)   \n",
    "    # return response\n",
    "    return [x['text'].strip() for x in response['choices']]\n",
    "def opt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)\n",
    "    response = opt_generator(prompt, max_new_tokens=256, max_length=len(prompt)+256, **kwargs)\n",
    "    print('Prompt length is {}'.format(len(prompt)))\n",
    "    # return [x['generated_text'].strip() for x in response]   \n",
    "    return [x['generated_text'][len(prompt):].strip() for x in response]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_orchestration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ARANGO_DB\"]=\"ipc_200\"\n",
    "nebula_db = NEBULA_DB()\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = nebula_db.get_llm_key()\n",
    "# nebula_db.change_db(\"nebula_playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = LlmTaskInternal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatabaseConnector().init_new_db('giltest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = nebula_db.gdb.connect_db('giltest_new2')\n",
    "print(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.has_collection('bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MovieImageId(\"Movies/-8125052309197429288\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.process_movie(\"Movies/1494834664894503945\")\n",
    "# task.nebula_db.get_movie_structure(\"Movies/1494834664894503945\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = HuggingFaceHub(repo_id=\"google/flan-t5-xl\")\n",
    "openai_llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/ul2\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16).to(\"cuda\")                                                                                                   \n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"google/ul2\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16) # google/flan-t5-xl\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-xxl\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "# model.cuda()\n",
    "\n",
    "# set_seed(14)\n",
    "# ul2_generator = transformer_pipeline('text-generation', model=\"google/ul2\", do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"[NLG] Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, solid man wiht a bald head. Mrs. Dursley was thin and blonde and more than the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbours. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. <extra_id_0>\"\n",
    "inputs = tokenizer(input_string, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_length=300)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.random.choice(task.s3_ids,2)\n",
    "target_id=np.random.choice(task.s3_ids,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = task.prompt_obj.generate_prompt(train_ids, target_id)\n",
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc = \"What would an American in France find really weird?\"\n",
    "# input_string = \"[NLG] \"+rc+\" <extra_id_0>\"\n",
    "# input_string = \"[S2S] \" + rc\n",
    "input_string = rc+\" <extra_id_0>\"\n",
    "inputs = tokenizer(input_string, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_length=300, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [HuggingFaceHub(repo_id=\"gpt2\"), OpenAI(temperature=0.2), HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0.7})]\n",
    "model_lab = ModelLaboratory.from_llms(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lab.compare(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(int(time.time()))\n",
    "opt_generator = transformer_pipeline('text-generation', model=\"facebook/opt-2.7b\", do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_execute(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-30b\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"google/ul2\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16).to(\"cuda\")                                                                                                   \n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"google/ul2\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16) # google/flan-t5-xl\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-30b\", low_cpu_mem_usage=True, torch_dtype=torch.bfloat16) .to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(rc, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(\"cuda\")\n",
    "outputs = model.generate(inputs, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc1 = tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rc1[len(rc):])\n",
    "# print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from movie.movie_db import MOVIE_DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ARANGO_DB\"] = \"giltest\"\n",
    "nre = MOVIE_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nre.get_movie(movie_id=\"Movies/-6013218496266483449\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nre.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ipc_images(n=100):\n",
    "    ipc_data = json.load(open(IPC_PATH,'r'))\n",
    "    download_path = \"/storage/vg_data/ipc_images\"\n",
    "    for obj in ipc_data[:n]:\n",
    "        print(\"Downloading \"+obj['url'])\n",
    "        if os.path.exists(os.path.join(download_path, os.path.split(obj['url'])[1])):\n",
    "            print(\"Already exists\")\n",
    "        else:\n",
    "            wget.download(obj['url'],out=download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_ipc_images(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [len(x['paragraph']) for x in ipc_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = {x['image_id']: x['paragraph'] for x in ipc_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = [len(z1[x]) for x in task.s3_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_db.write_doc_by_key({'gil': 94, 'dan': 7, 'tali': 20},collection_name='giltest', overwrite = True, key_list=['gil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nebula_db.get_doc_by_key(image_id_as_dict(mid),'s4_visual_clues')\n",
    "#nebula_db.get_doc_by_key(image_id_as_dict(mid),'s4_visual_clues')\n",
    "# nebula_db.get_movie_frame_from_collection(mid)\n",
    "#nebula_db.write_doc_by_key({'gil': 5, 'dan': 15, 'tali': 20},collection_name='giltest', overwrite = True, key_list=['gil'])\n",
    "#list(nebula_db.db.collection('giltest').find({}))\n",
    "\n",
    "# ppl.get_new_movies(\"2bda2110-bcb8-4a6d-a334-455a1cf30c6c\",\"llm\")\n",
    "\n",
    "# test_pipeline_task(\"0cb4accc-14ff-46f7-bbb5-55b085afabeb\")\n",
    "\n",
    "# mid = MovieImageId(\"Movies/-6295549713179447550\",0)\n",
    "# mobj = task.nebula_db.get_movie_frame_from_collection(mid)\n",
    "# mobj['url']\n",
    "\n",
    "# task.prompt_obj.get_prompt(2369414)\n",
    "\n",
    "# rc = task.process_target_id(mid,image_url=mobj['url'],n=5)\n",
    "\n",
    "# task.nebula_db.write_movie_frame_doc_to_collection(mid,rc,LLM_OUTPUT_COLLECTION)\n",
    "\n",
    "# task.process_movie(\"Movies/8477229371170297745\",n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobj = nebula_db.get_movie_frame_from_collection(mid)\n",
    "os.path.split(mobj['url'])[1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = VGEvaluation()\n",
    "def process_recall(mid: MovieImageId, **kwargs):\n",
    "    doc = nebula_db.get_movie_frame_from_collection(mid,collection=LLM_OUTPUT_COLLECTION)\n",
    "    target_id = os.path.split(doc['url'])[1].split('.')[0]             # Get filename without the .jpg part\n",
    "    sg = get_sc_graph(int(target_id))\n",
    "    gt_triplets = tuples_from_sg(sg)\n",
    "    pred_triplets = doc['gpt_triplets']\n",
    "    # pred_triplets = doc['triplets']\n",
    "    # print(\"Ground Triplets:\")\n",
    "    # print(gt_triplets)\n",
    "    # print(\"Pred triplets:\")\n",
    "    # print(pred_triplets)\n",
    "    recall = evaluator.recall_triplets_mean(gt_triplets,pred_triplets, **kwargs)\n",
    "    precision = evaluator.recall_triplets_mean(pred_triplets,gt_triplets, **kwargs)\n",
    "    return {\n",
    "        'image_id': target_id,\n",
    "        'mean_recall': float(recall),\n",
    "        'mean_precision': float(precision)\n",
    "    }\n",
    "\n",
    "def worker_process_recall(mobj):\n",
    "        assert(mobj['mdfs'] == [[0]])\n",
    "        mid = MovieImageId(mobj['_id'],0)\n",
    "        curr_key = {'movie_id': mobj['_id'], 'benchmark_name': mobj['misc']['benchmark_name'], 'benchmark_tag': mobj['misc']['benchmark_tag']}\n",
    "        curr_doc = nebula_db.get_doc_by_key2(curr_key, EVAL_COLLECTION_NAME)\n",
    "        if curr_doc:\n",
    "            print(\"Found existing eval result, moving on: \")\n",
    "            print(curr_doc.pop())\n",
    "            return None\n",
    "        try:\n",
    "            rc = process_recall(mid)\n",
    "        except:\n",
    "            print(\"Failed to evaluate mid: {}\".format(mid[0]))\n",
    "            return False\n",
    "        rc['movie_id']=mid[0]\n",
    "        rc['benchmark_name']=mobj['misc']['benchmark_name']\n",
    "        rc['benchmark_tag']=mobj['misc']['benchmark_tag']\n",
    "        print(rc)\n",
    "        rc1 = nebula_db.write_doc_by_key(rc,EVAL_COLLECTION_NAME,key_list=['image_id', 'movie_id', 'benchmark_name','benchmark_tag'])\n",
    "        print(\"Result from writing:\")\n",
    "        print(rc1)\n",
    "        return rc\n",
    "    \n",
    "def process_benchmark(benchmark_name):\n",
    "    results = []\n",
    "    if not nebula_db.db.has_collection(EVAL_COLLECTION_NAME):\n",
    "        nebula_db.db.create_collection(EVAL_COLLECTION_NAME)\n",
    "    benchmark = list(nebula_db.db.collection('Movies').find({'misc.benchmark_name': benchmark_name}))\n",
    "    print(\"Processing {} items\".format(len(benchmark)))\n",
    "    for mobj in benchmark:\n",
    "        assert(mobj['mdfs'] == [[0]])\n",
    "        mid = MovieImageId(mobj['_id'],0)\n",
    "        curr_key = {'movie_id': mobj['_id'], 'benchmark_name': mobj['misc']['benchmark_name'], 'benchmark_tag': mobj['misc']['benchmark_tag']}\n",
    "        curr_doc = nebula_db.get_doc_by_key2(curr_key, EVAL_COLLECTION_NAME)\n",
    "        if curr_doc:\n",
    "            print(\"Found existing eval result, moving on: \")\n",
    "            print(curr_doc.pop())\n",
    "            continue\n",
    "        try:\n",
    "            rc = process_recall(mid)\n",
    "        except:\n",
    "            print(\"Failed to evaluate mid: {}\".format(mid[0]))\n",
    "            continue\n",
    "        rc['movie_id']=mid[0]\n",
    "        rc['benchmark_name']=mobj['misc']['benchmark_name']\n",
    "        rc['benchmark_tag']=mobj['misc']['benchmark_tag']\n",
    "        print(rc)\n",
    "        results.append(rc)\n",
    "        rc1 = nebula_db.write_doc_by_key(rc,EVAL_COLLECTION_NAME,key_list=['image_id', 'movie_id', 'benchmark_name','benchmark_tag'])\n",
    "        print(\"Result from writing:\")\n",
    "        print(rc1)\n",
    "    return results\n",
    "\n",
    "\n",
    "def mp_process_benchmark(benchmark_name):\n",
    "    if not nebula_db.db.has_collection(EVAL_COLLECTION_NAME):\n",
    "        nebula_db.db.create_collection(EVAL_COLLECTION_NAME)\n",
    "    benchmark = list(nebula_db.db.collection('Movies').find({'misc.benchmark_name': benchmark_name}))\n",
    "    print(\"Processing {} items\".format(len(benchmark)))\n",
    "    with mp.Pool(processes=6) as pool:\n",
    "        results = pool.map(worker_process_recall, benchmark)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MovieImageId(\"Movies/-233116329437070952\",0)\n",
    "# process_recall(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('forkserver')\n",
    "p = mp.Process(target=process_recall, args=(mid,))\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_db.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_db.write_doc_by_key(bla,EVAL_COLLECTION_NAME,key_list=['image_id','benchmark_name','benchmark_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = process_benchmark('ipc_200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla['mean_recall'] = float(bla['mean_recall'])\n",
    "bla['mean_precision'] = float(bla['mean_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = list(nebula_db.db.collection('Movies').find({'misc.benchmark_name': 'ipc_400'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MovieImageId(\"Movies/3371631599022929731\",264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = nebula_db.get_doc_by_key2(image_id_as_dict(mid), EVAL_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_data = json.load(open(IPC_PATH,'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = nebula_db.get_doc_by_key2({},'IPC_GT')\n",
    "ids = [x['image_id'] for x in rc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,obj in enumerate(ipc_data):\n",
    "    if obj['image_id'] in ids:\n",
    "        # print('image_id {} already exists, moving on'.format(obj['image_id']))\n",
    "        continue\n",
    "    rc = {\n",
    "        'image_id': obj['image_id'],\n",
    "        'ipc_caption': obj['paragraph'],\n",
    "        'triplets': [list(x) for x in tuples_from_sg(get_sc_graph(obj['image_id']))]\n",
    "    }\n",
    "    print('Writing image_id {} ({})'.format(obj['image_id'],i))\n",
    "    nebula_db.write_doc_by_key(rc,'IPC_GT',key_list=['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_db.get_movie_frame_from_collection(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = benchmark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in benchmark[1:]:\n",
    "    del obj['_rev']\n",
    "    obj['misc']['benchmark_tag'] = 'test2'\n",
    "    nebula_db.write_doc_by_key(obj,'Movies',overwrite=True,key_list=['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_db.write_doc_by_key(obj,'Movies',overwrite=True,key_list=['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = list(nebula_db.db.collection('Movies').find({'misc.benchmark_name': 'ipc_200'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in benchmark[:2]:\n",
    "    mid = MovieImageId(x['_id'],0)\n",
    "    obj = nebula_db.get_movie_frame_from_collection(mid,LLM_OUTPUT_COLLECTION)\n",
    "    if 'gpt_triplets2' in obj.keys():\n",
    "        print(\"mid {} already has gpt_triplets, moving on\".format(mid))\n",
    "        continue\n",
    "    del obj['_rev']\n",
    "    cand = obj['candidate']\n",
    "    gpt_triplets = get_likey_tuples_from_paragraph(cand)\n",
    "    try:\n",
    "        # print(type(gpt_triplets[0]))\n",
    "        obj['gpt_triplets2'] = gpt_triplets[0]\n",
    "        nebula_db.write_doc_by_key(obj,LLM_OUTPUT_COLLECTION,overwrite=True,key_list=['movie_id', 'frame_num'])\n",
    "        print(\"Processed gpt triplets for mid {}\".format(mid))\n",
    "    except:\n",
    "        print(\"Failed to parse triplets for mid {}\".format(mid))\n",
    "        print(gpt_triplets)\n",
    "\n",
    "    \n",
    "    # print(obj['triplets'])\n",
    "    # print(gpt_triplets)\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
